{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langchain langchain_community langchain-chroma pypdf langchain_text_splitters langchain_cohere tenacity python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "loader = PyPDFLoader(\"kanoni.pdf\")\n",
    "pages = loader.load()\n",
    "text = \"\"\n",
    "for page in pages:\n",
    "    text += page.page_content\n",
    "\n",
    "# print first 1000 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"თავი [IVXLCDM]+\", \"მუხლი \\d+\"],\n",
    "    is_separator_regex=True,\n",
    ")\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\Halvadar\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "# embed chunks\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "import os\n",
    "# store chunks in chroma\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"kanoni\",\n",
    "    embedding_function=CohereEmbeddings(cohere_api_key=os.environ[\"COHERE_API_KEY\"], model=\"embed-multilingual-light-v3.0\"),\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    "    create_collection_if_not_exists=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 1\n",
      "Processing batch 2 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 2\n",
      "Processing batch 3 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 3\n",
      "Processing batch 4 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 4\n",
      "Processing batch 5 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 5\n",
      "Processing batch 6 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 6\n",
      "Processing batch 7 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 7\n",
      "Processing batch 8 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 8\n",
      "Processing batch 9 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 9\n",
      "Processing batch 10 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 10\n",
      "Processing batch 11 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 11\n",
      "Processing batch 12 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 12\n",
      "Processing batch 13 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 13\n",
      "Processing batch 14 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 14\n",
      "Processing batch 15 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 15\n",
      "Processing batch 16 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 16\n",
      "Processing batch 17 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 17\n",
      "Processing batch 18 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 18\n",
      "Processing batch 19 of 103\n",
      "embedding batch\n",
      "adding to vector store\n",
      "Successfully added batch 19\n",
      "Processing batch 20 of 103\n",
      "embedding batch\n",
      "adding to vector store\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "@retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(5))\n",
    "def get_embeddings(texts):\n",
    "    embeddings = CohereEmbeddings(cohere_api_key=os.environ[\"COHERE_API_KEY\"], model=\"embed-multilingual-light-v3.0\", )\n",
    "    return embeddings.embed(texts=texts,input_type=\"search_document\")\n",
    "\n",
    "\n",
    "\n",
    "# Add texts in smaller batches with delay\n",
    "batch_size = 5  # Reduced batch size\n",
    "total_batches = len(chunks) // batch_size + (1 if len(chunks) % batch_size > 0 else 0)\n",
    "\n",
    "for i in range(0, len(chunks), batch_size):\n",
    "    try:\n",
    "        print(f\"Processing batch {i//batch_size + 1} of {total_batches}\")\n",
    "        batch = chunks[i:i+batch_size]\n",
    "        print(\"embedding batch\")\n",
    "        # Get embeddings for the batch\n",
    "        embeddings = get_embeddings(batch)\n",
    "        print(\"adding to vector store\")\n",
    "        # Add texts and embeddings to the vector store\n",
    "        vector_store.add_texts(texts=batch, embeddings=embeddings)\n",
    "        \n",
    "        print(f\"Successfully added batch {i//batch_size + 1}\")\n",
    "        time.sleep(1)  # Increased delay between batches\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {i//batch_size + 1}: {str(e)}\")\n",
    "        time.sleep(2)  # Longer delay if an error occurs\n",
    "\n",
    "print(\"Finished processing all batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generates a list of rectangular boxes for the target content regions. Diﬀerent\n",
      "from traditional methods, it relies on deep convolutional neural networks rather\n",
      "than manually curated rules to identify content regions. It is formulated as an\n",
      "object detection problem and state-of-the-art models like Faster R-CNN [ 28] and\n",
      "Mask R-CNN [ 12] are used. This yields prediction results of high accuracy and\n",
      "makes it possible to build a concise, generalized interface for layout detection.\n",
      "LayoutParser , built upon Detectron2 [ 35], provides a minimal API that can\n",
      "perform layout detection with only four lines of code in Python:\n",
      "1import layoutparser as lp\n",
      "2image = cv2 . imread (\" image_file \") # load images\n",
      "3model = lp. Detectron2LayoutModel (\n",
      "4 \"lp :// PubLayNet / faster_rcnn_R_50_FPN_3x / config \")\n",
      "5layout = model . detect ( image )\n",
      "LayoutParser provides a wealth of pre-trained model weights using various\n",
      "datasets covering diﬀerent languages, time periods, and document types. Due to\n"
     ]
    }
   ],
   "source": [
    "# Add the following code to retrieve the first embedding\n",
    "results = vector_store.similarity_search(query=\"ამოღებულია\")\n",
    "\n",
    "# Print the first embedding\n",
    "print(results[0].page_content)\n",
    "\n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
